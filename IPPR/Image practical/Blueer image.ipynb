{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2e12eb-0fcf-4479-9f2a-0529acca5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load image\n",
    "img = cv2.imread(\"D://SJC//Image Processing//images//blur.jpg\")\n",
    "#img = cv2.imread(\"C://Users//IT//Desktop//IMG_20250210_103500_1.jpg\")\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# blur\n",
    "blur = cv2.GaussianBlur(gray, (0,0), sigmaX=33, sigmaY=33)\n",
    "\n",
    "# divide\n",
    "divide = cv2.divide(gray, blur, scale=255)\n",
    "\n",
    "# otsu threshold\n",
    "thresh = cv2.threshold(divide, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\n",
    "# write result to disk\n",
    "cv2.imwrite(\"hebrew_text_division.jpg\", divide)\n",
    "cv2.imwrite(\"hebrew_text_division_threshold.jpg\", thresh)\n",
    "\n",
    "\n",
    "# display it\n",
    "cv2.imshow(\"gray\", gray)\n",
    "cv2.imshow(\"divide\", divide)\n",
    "cv2.imshow(\"thresh\", thresh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "114d0a3d-b992-4ebf-904d-0afc8b91f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Read the image\n",
    "img = cv2.imread(\"D://SJC//Image Processing//images//blur.jpg\")\n",
    "# convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Apply Gaussian Blur\n",
    "blurred_image = cv2.GaussianBlur(img, (5, 5), 0)  # (5, 5) is the kernel size, adjust as needed\n",
    "\n",
    "# Save or display the result\n",
    "\n",
    "cv2.imshow('blurred_image.jpg', blurred_image)\n",
    "cv2.imshow('Original Image', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d406b1-4eb3-4565-a855-8b2df15fa8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(\"D://SJC//Image Processing//images//blur.jpg\")\n",
    "\n",
    "# Apply a 3x3 averaging filter\n",
    "kernel = np.ones((3, 3), np.float32) / 9\n",
    "filtered_image = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "# Save or display the result\n",
    "cv2.imshow('spatial_filtered_image.jpg', filtered_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5b9f322-3852-4d69-8bca-f422e8877688",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(\"D://SJC//Image Processing//images//image1.jpg\")\n",
    "\n",
    "# Apply Gaussian Blur\n",
    "blurred_image = cv2.GaussianBlur(image, (5, 5), 0)  # (5, 5) is the kernel size\n",
    "\n",
    "# Save or display the result\n",
    "cv2.imwrite('smoothed_image.jpg', blurred_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cb804bd-11d7-4b68-81d3-1c220c82a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Load the image\n",
    "image = cv2.imread(\"D://SJC//Image Processing//images//blur.jpg\")\n",
    "# Apply median filtering\n",
    "median_filtered_image = cv2.medianBlur(image, 5)\n",
    "\n",
    "# Display the original and median filtered image\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Median Filtering', median_filtered_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1ee03dc-bc4c-490d-afd5-2568369b5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Load the image\n",
    "image = cv2.imread(\"D://SJC//Image Processing//images//blur.jpg\")\n",
    "# Apply bilateral filtering\n",
    "bilateral_filtered_image = cv2.bilateralFilter(image, 9, 75, 75)\n",
    "# Display the original and bilateral filtered image\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Bilateral Filtering', bilateral_filtered_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d62291-c461-4fba-aa37-7b6646564b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Unsharp Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1edab11-f067-4281-be8c-15c14db5bb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# Load the image\n",
    "image = cv2.imread(\"D://SJC//Image Processing//images//blur.jpg\")\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Apply Gaussian smoothing to create a blurred version of the\n",
    "image\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "# Perform unsharp masking\n",
    "sharpened_image = cv2.addWeighted(gray_image, 1.5,\n",
    "blurred_image, -0.5, 0)\n",
    "# Display the original and sharpened image\n",
    "cv2.imshow('Original Image', gray_image)\n",
    "cv2.imshow('Unsharp Masking', sharpened_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b52620-5467-4750-999e-4d7c61ccacee",
   "metadata": {},
   "outputs": [],
   "source": [
    "High Pass Filtering: Emphasizes high-frequency components in an\n",
    "image, effectively enhancing edges and fine details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "815163ba-e841-41b0-a86c-6f8b70297533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "# Load the image\n",
    "image = cv2.imread(\"D://SJC//Image Processing//images//blur.jpg\")\n",
    "# Convert image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Apply Gaussian smoothing to create a blurred version of the\n",
    "image\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "\n",
    "# Perform high pass filtering by subtracting the blurred image from the original\n",
    "high_pass_image = cv2.subtract(gray_image, blurred_image)\n",
    "# Display the original and high pass filtered image\n",
    "cv2.imshow('Original Image', gray_image)\n",
    "cv2.imshow('High Pass Filtering', high_pass_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4dae1-dabb-48de-95b2-b3234b59c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sharpening: Applies a Laplacian filter to highlight areas of rapid\n",
    "intensity change, thereby increasing image contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c7cc56f-8f2c-4996-86fc-82ba2ab181e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# Load the image\n",
    "image = cv2.imread(\"D://SJC//Image Processing//images//blur.jpg\")\n",
    "# Convert image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Apply Laplacian filter\n",
    "laplacian_image = cv2.Laplacian(gray_image, cv2.CV_64F)\n",
    "# Normalize the output to make it suitable for display\n",
    "laplacian_image = cv2.normalize(laplacian_image, None, 0, 255,\n",
    "cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "# Display the original and sharpened image\n",
    "cv2.imshow('Original Image', gray_image)\n",
    "cv2.imshow('Laplacian Sharpening', laplacian_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bf8bde-9b31-4807-b781-40ba1d6a2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Strength Parameter in Unsharp Masking\n",
    "\n",
    "The strength parameter determines the contribution of the high-\n",
    "frequency components to the final sharpened image. Higher values\n",
    "\n",
    "result in a stronger sharpening effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f6c65a8-9b8a-4ecb-bf22-fb863531cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# Load the image\n",
    "image = cv2.imread(\"D://SJC//Image Processing//images//image1.jpg\")\n",
    "# Convert image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Gaussian smoothing to create a blurred version of the\n",
    "image\n",
    "blurred_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "# Adjust the strength parameter to control the sharpening effect\n",
    "sharpened_image_strong = cv2.addWeighted(gray_image, 1.8,\n",
    "blurred_image, -0.8, 0)\n",
    "sharpened_image_mild = cv2.addWeighted(gray_image, 1.3,\n",
    "blurred_image, -0.3, 0)\n",
    "# Display the original and sharpened images\n",
    "cv2.imshow('Original Image', gray_image)\n",
    "cv2.imshow('Sharpened Image (Strong)',\n",
    "sharpened_image_strong)\n",
    "cv2.imshow('Sharpened Image (Mild)', sharpened_image_mild)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b05a20d2-5859-4f67-92d9-424b73edaadd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+F075 (3676024731.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[34], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m     The conservative filters are preferred to remove salt and pepper noise. Determines the\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+F075\n"
     ]
    }
   ],
   "source": [
    "Conservative Image Filtering\n",
    " The conservative filters are preferred to remove salt and pepper noise. Determines the\n",
    "minimum intensity and maximum intensity within a neighborhood of a pixel.\n",
    " If the intensity of the center pixel is greater than the maximum value it is replaced by the\n",
    "maximum value.\n",
    " If it is less than the minimum value than it is replaced by the minimum value.\n",
    " The conservative filter preserves edges of the images but does not remove speckle noise.\n",
    "the filter is not able to remove as much salt-and-pepper noise as a median filter (although it\n",
    "does preserve more detail.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8058e784-ed59-462d-8d77-7e2e69ece9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def conservative_filter(image, kernel_size):\n",
    "    # Convert the image to grayscale if it's not already\n",
    "    if len(image.shape) == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Pad the image to handle borders\n",
    "    pad_size = kernel_size // 2\n",
    "    padded_image = np.pad(image, pad_size, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Create an output image to store the filtered result\n",
    "    filtered_image = np.copy(image)\n",
    "    \n",
    "    # Iterate over each pixel in the original image\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            # Extract the neighborhood\n",
    "            neighborhood = padded_image[i:i+kernel_size, j:j+kernel_size]\n",
    "            \n",
    "            # Find the minimum and maximum values in the neighborhood\n",
    "            min_val = np.min(neighborhood)\n",
    "            max_val = np.max(neighborhood)\n",
    "            \n",
    "            # Get the current pixel value\n",
    "            current_val = image[i, j]\n",
    "            \n",
    "            # Adjust the pixel value based on the neighborhood extremes\n",
    "            if current_val < min_val:\n",
    "                filtered_image[i, j] = min_val\n",
    "            elif current_val > max_val:\n",
    "                filtered_image[i, j] = max_val\n",
    "            else:\n",
    "                filtered_image[i, j] = current_val\n",
    "    \n",
    "    return filtered_image\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread(\"D://SJC//Image Processing//images//New_Adhar Card.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply conservative filtering with a 3x3 kernel\n",
    "kernel_size = 3\n",
    "filtered_image = conservative_filter(image, kernel_size)\n",
    "\n",
    "# Display the original and filtered images\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Filtered Image', filtered_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb126424-b678-49ef-b122-95434f536e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
